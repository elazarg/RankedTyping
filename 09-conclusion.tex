\section{Conclusion}
\label{sec:conclusion}

We introduced a small, compositional static analysis that makes path-insensitive precision loss explicit via a graded algebra of types. Base types and $\Any$ carry a nonnegative grade; same-grade heterogeneous joins are conservative, and grades increase only when the analysis commits to a base after imprecision ($\Any^{i}\!\le\!X^{\,i+1}$). We instantiated this domain in a standard abstract interpreter for a \textsf{while}-language, proved monotonicity and soundness (as a may-analysis), and explained termination either by a simple grade-capping widening or by a finite ghost-set product domain. The grade and its associated culprit-set provide actionable diagnostics: they localize where assumptions were forced and bound how much imprecision a value carries.

The approach is deliberately cast-free and leaves operational semantics unchanged. It relates cleanly to gradual typing: collapsing grades and adding consistency/casts recovers a conventional gradual system, while retaining the graded domain yields an ``unfolded'' static account of imprecision provenance. Extensions-grade-parametric function signatures, grade-as-effect grades, shape-preserving joins, SSA $\phi$-site instrumentation, and a gradual mode-fit without disturbing the core algebra.

Limitations are clear: the analysis is path-insensitive, does not guarantee absence of runtime type errors, and we have not attempted an empirical evaluation here. The \S\ref{sec:future} agenda outlines next steps (graded semantics, precision recovery, mechanization). The core contribution is a minimal algebra and analysis that expose, rather than collapse, the structure of precision loss-yielding principled and explainable static diagnostics.
