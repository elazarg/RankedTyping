\section{Extensions}
\label{sec:extensions}

We sketch several conservative extensions of the core system. Each is named and can be adopted independently.

\subsection{\textsc{E1: Grade–Parametric Function Signatures \& Inference}}
\paragraph{Types.}
Augment types with (first–order) function arrows and grade quantification:
\[
\tau ::= \cdots \;\mid\; \tau \to \tau 
\qquad\qquad
\sigma ::= \forall \vec{i}.\ \tau
\]
where grade variables range over $\mathbb{N}$ and may appear in superscripts.
Typical shapes:
\[
\forall i.\ X^{i} \to X^{\,i+\alpha}
\qquad
\forall i,j.\ X^{i}\times Y^{j} \to Z^{\,\max(i,j)+\beta}
\]
with fixed nonnegative \emph{grade shifts} $\alpha,\beta \in \mathbb{N}$.

\paragraph{Examples.}
\begin{align*}
\textsf{id}_X &: \forall i.\ X^{i} \to X^{i} 
\\
\textsf{add1} &: \forall i.\ \textsf{Int}^{i} \to \textsf{Int}^{i}
\\
\textsf{concat\_a} &: \forall i.\ \textsf{String}^{i} \to \textsf{String}^{i}
\\
\textsf{downcast}_X &: \forall i.\ \textsf{Any}^{i} \to X^{\,i+1} \quad\text{(adds one grade)}
\\
\textsf{mix} &: \forall i,j.\ \textsf{Int}^{i}\times \textsf{String}^{j} \to \textsf{Any}^{\,\max(i,j)+1}
\end{align*}

\paragraph{Composition law.}
If $f:\forall i.\ X^{i}\!\to\! X^{\,i+\alpha}$ and $g:\forall i.\ X^{i}\!\to\! X^{\,i+\beta}$,
then $f\circ g:\forall i.\ X^{i}\!\to\! X^{\,i+\alpha+\beta}$.
For binary forms, grade shifts compose with $\max$ in the obvious way:
if $h:\forall i,j.\ X^{i}\times Y^{j}\to Z^{\,\max(i,j)+\gamma}$ and
$k:\forall i.\ Z^{i}\to Z^{\,i+\delta}$, then
$k\circ h:\forall i,j.\ X^{i}\times Y^{j}\to Z^{\,\max(i,j)+\gamma+\delta}$.

\paragraph{Typing (sketch).}
Application instantiates grade variables with concrete grades from the argument types,
then checks subtyping on bases and enforces the grade output equation given by the signature
(e.g., $i'\!=\!i{+}\alpha$, or $k'\!=\!\max(i,j){+}\beta$).

\paragraph{Inference.}
Associate unknown nonnegative shifts (e.g., $\alpha,\beta,\dots$) to function bodies and generate constraints from each use:
\[
r_{\text{out}} \;\ge\; r_{\text{in}} + \alpha
\qquad\text{or}\qquad
r_{\text{out}} \;\ge\; \max(r_1,r_2) + \beta
\]
together with base-type constraints.
Solve the resulting monotone system over $(\mathbb{N},\le)$ using least solutions
(e.g., Kleene iteration on $\max$/$+$ constraints); the \emph{principal} signature takes the least satisfying shifts.

\medskip

\subsection{\textsc{E2: Grades as Effects (Graded)}}
Treat ``grade increase'' as an effect grade.
A typing judgment carries a grade $g\in\mathbb{N}$; arrows become graded:
\(
\Gamma \vdash e : \tau \;!\; g
\)
and composition obeys $g$-addition while multi-argument operators use $g=\max$.
This yields a small-step algebra matching the grade equations in \textsc{E1}.

\subsection{\textsc{E3: Bounded–Grade Modes}}
Introduce a modal cap $\square_{\le k}$ that restricts programs (or interfaces) to yield grades $\le k$.
Useful for ``precision budgets'' and for rejecting overly imprecise code at module boundaries.

\subsection{\textsc{E4: Grade–Aware Cast Calculus}}
Add explicit casts $\langle \tau \Rightarrow \tau'\rangle e$ with types such as
$\forall i.\ \textsf{Any}^{i} \to X^{\,i+1}$,
and a runtime that either succeeds (raising grade by $+1$) or signals a checked failure.
This supports a \emph{bounded blame} story where failures are charged to specific cast sites.

\subsection{\textsc{E5: Shape–Preserving Joins for Data Types}}
Extend the lattice structurally:
\[
\textsf{List}\ X^{i} \;\sqcup\; \textsf{List}\ Y^{j}
\;=\; \textsf{List}\ \textsf{Any}^{\,\max(i,j)}
\]
(and analogously for products/sums), lifting the base rule into type constructors.

\subsection{\textsc{E6: SSA \& \texorpdfstring{$\phi$}{phi}–Site Instrumentation}}
In SSA, $\phi$–nodes are explicit choke points.
Label them with site IDs, propagate \emph{ghost culprit sets} alongside grades, and surface precise diagnostics:
``$x$ imprecise due to $\phi$ at blocks \#7,\#12''.

\subsection{\textsc{E7: Correlation Recovery (Selective Refinement)}}
Augment the analysis with lightweight relational facts (e.g., guard-sensitivity at chosen joins),
allowing post–join refinement that can \emph{lower} computed grades without changing the core lattice.

\subsection{\textsc{E8: Higher–Order Grade Polymorphism}}
Generalize \textsc{E1} to higher order:
\[
\textsf{map} : \forall i.\ (\textsf{Int}^{i}\!\to\!\textsf{Int}^{\,i+\alpha}) \to
(\textsf{List}\ \textsf{Int})^{i} \to (\textsf{List}\ \textsf{Int})^{\,i+\alpha}
\]
with inference propagating the shift $\alpha$ through higher-order uses.

\subsection{\textsc{E9: Interop with Gradual Typing}}
Keep our lattice (joins, grades) but add a consistency–based unknown $\star$ and casts.
Grade–aware casts (as in \textsc{E4}) could supply \emph{budgets} to a gradual system, while preserving our per–program convergence guarantees.

\subsection{\textsc{E10: Gradual Typing as a Special Case}}
\label{sec:gradual-special-case}

Standard gradual typing is not merely analogous to graded typing---it is a \emph{special case}, obtained by collapsing the grade lattice.
The entire behavioral difference between the two systems reduces to a single function: the grade successor used in coercion.

\paragraph{Collapsed grade lattice.}
The graded system uses the full lattice $\bot < 0 < 1 < 2 < \cdots < \infty$.
Gradual typing operates on the collapsed three-element lattice $\{\bot, 0, \infty\}$, where every non-zero finite grade is identified with~$\infty$.
Formally, the only change is the \emph{successor function} used in coercion ($\ceil{\cdot}_X$):
\[
\begin{array}{r@{\;:\;}l@{\qquad}r@{\;:\;}l}
\multicolumn{2}{c}{\textbf{Graded}} & \multicolumn{2}{c}{\textbf{Gradual}} \\[3pt]
\mathrm{succ}(\bot) & 0 & \mathrm{succ}_\infty(\bot) & 0 \\
\mathrm{succ}(n) & n{+}1 & \mathrm{succ}_\infty(n) & \infty \quad(n\ge 0)
\end{array}
\]
The coercion function $\ceil{\tau}_X$ promotes a type $\tau$ to base $X$, incrementing the grade via $\mathrm{succ}$ when a downcast $\Any^{i}\!\le\!X^{\mathrm{succ}(i)}$ is needed.
Under $\mathrm{succ}_\infty$, any such downcast immediately sends the grade to~$\infty$, which is exactly the behavior of the unknown type~$?$ in standard gradual typing: once a value passes through a dynamic check, all downstream types carry~$\infty$ (the ``dynamic'' grade).

\paragraph{Implementation: a single parameterized module.}
In the implementation (\S\ref{sec:implementation}), the abstract interpreter is parameterized over the coercion function via an OCaml functor.
The graded and gradual instantiations differ only in the definition of $\mathrm{succ}$:
\begin{itemize}
  \item \textbf{Graded:} $\mathrm{succ}(n) = n{+}1$ (fine-grained distance tracking).
  \item \textbf{Gradual:} $\mathrm{succ}_\infty(n) = \infty$ for $n \ge 0$ (binary ``known/unknown'' distinction).
\end{itemize}
All other components---parsing, join, subtyping, cost-based interpretation selection, fixed-point iteration---are shared verbatim.

\paragraph{Erasure.}
Define a collapse/erasure from graded to gradual types by
\[
\mathrm{erase}(\Int^{i})=\Int,\quad
\mathrm{erase}(\String^{i})=\String,\quad
\mathrm{erase}(\Bool^{i})=\Bool,\quad
\mathrm{erase}(\Any^{i})=?,
\]
extended homomorphically over type constructors.
The gradual instantiation (using $\mathrm{succ}_\infty$) produces exactly the types that erasure would produce from the graded output: this is a \emph{consequence} of the collapsed lattice, not an independent definition.

\paragraph{Precision comparison.}
Programs where the graded system assigns finite grades ($\Int^{1}$, $\Int^{2}$) receive $\Int^{\infty}$ under the gradual instantiation---the multi-level ranking is lost.
See Example~12 in \S\ref{sec:examples} for a concrete comparison.

\paragraph{Consistency and casts.}
On erased types, a standard consistency relation \(A \mathrel{\sim} B\) holds iff
(i) \(A=B\); or (ii) either side is \(?\); or (iii) type constructors match and components are pairwise consistent.
The grade-aware downcast from \textsc{E4}, typed as
$\forall i.\ \Any^{i} \to X^{\,\mathrm{succ}(i)}$,
specializes to $\Any^{i} \to X^{\infty}$ in the gradual mode.

\paragraph{Precision join correspondence.}
For base/shape-preserving cases,
\[
\mathrm{erase}(\tau_1 \sqcup \tau_2)
\;=\;
\mathrm{erase}(\tau_1)\ \sqcup_{\!\sim}\ \mathrm{erase}(\tau_2),
\]
where \(\sqcup_{\!\sim}\) is the usual precision join in gradual typing (e.g., \(\Int\sqcup_{\!\sim}\String=?\), and constructors lift \(?\) componentwise).

\paragraph{Status of obligations.}
\begin{itemize}
  \item \emph{Conservative extension}: resolved by construction. A purely static program (all grades $0$) is well-typed under both instantiations, since $\mathrm{succ}$ is never invoked.
  \item \emph{Blame/coherence}: standard cast meta-theory over the erased core. Open.
  \item \emph{Gradual guarantee}: precision monotonicity phrased on erased types. Open.
  \item \emph{Embedding}: the graded system embeds into the gradual system by erasure; the reverse picks finite-grade representatives. Open.
\end{itemize}

\subsection{\textsc{E11: Metric Toggle: Downcast vs.\ Merge Counting}}

Our core uses the \emph{downcast-counting} metric:
heterogeneous same-grade joins return \(\Any^{r}\) (no bump), and grades increase only at subtyping steps \(\Any^{i}\le X^{\,i+1}\) when a base is demanded.
For completeness, we note an alternative \emph{merge-counting} variant and their relationship.

\paragraph{Downcast-counting (core).}
Subtyping generators:
\[
\inferrule*{ }{X^{i}\le \Any^{i}}
\qquad
\inferrule*{ }{\Any^{i}\le X^{\,i+1}}
\quad(i\in\mathbb{N},\ X\in\{\Int,\String,\Bool\})
\]
Join (analysis-time LUB w.r.t.\ \(\le\)): promote to common grade \(r\), then
\(X^{r}\sqcup Y^{r}=\Any^{r}\) for \(X\neq Y\), and \(\Any^{r}\) absorbs.

\paragraph{Merge-counting (alternative).}
Same subtyping as the core, but analysis join \emph{increments} on heterogeneous bases:
after promotion to grade \(r\), set \(X^{r}\sqcup Y^{r}=\Any^{\,r+1}\) for \(X\neq Y\).
Downcasts \(\Any^{i}\le X^{i}\) do not raise the grade in this variant.

\paragraph{Equivalence up to shift (informal).}
For straight-line code that immediately demands a base after each loss of correlation, both metrics produce the same grades up to a constant shift.
When imprecision is carried without commitment (values remain at \(\Any\) across joins), the metrics diverge:
merge-counting increments at the join; downcast-counting increments later, at the first demanded base.
Both variants preserve per-program finiteness and the bounded-blame story (culprit sets attach to, respectively, join sites vs.\ use sites).

\paragraph{Choosing a metric.}
Downcast-counting aligns grades with \emph{assumptions the analyzer had to make} at concrete use sites (casts/coercions);
merge-counting aligns grades with \emph{where correlation was lost} in control flow.
Either can be selected without changing the concrete semantics or the core lattice; only the analysis join and the intended diagnostic narrative differ.

\paragraph{Summary.}
\textsc{E1} makes grades first–class in function specifications with a simple, solvable constraint language.
\textsc{E2}–\textsc{E9} explore orthogonal axes: effects, budgets, casts, richer types, SSA integration, precision recovery, higher order, and interop.
\textsc{E10} is realized concretely: the gradual typing instantiation is implemented and validated alongside the graded system, confirming that a single function ($\mathrm{succ}$) separates the two.
